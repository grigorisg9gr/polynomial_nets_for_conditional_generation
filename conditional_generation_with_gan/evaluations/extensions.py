import os
import sys
import math

import numpy as np
from PIL import Image
import scipy.linalg

import chainer
import chainer.cuda
from chainer import Variable
from chainer import serializers
from chainer import cuda
import chainer.functions as F
from chainer.training import extensions

sys.path.append(os.path.dirname(__file__))
sys.path.append('../')
from source.inception.inception_score import inception_score, Inception
from source.links.sn_convolution_2d import SNConvolution2D
from source.functions.max_sv import max_singular_value
from numpy.linalg import svd
try:
    from skl_groups.divergences import KNNDivergenceEstimator
except ImportError:
    pass
# # even though NDB is imported, its evaluation was not used for this 
# # project; it remains here for legacy mode.
from evaluations.ndb import NDB

# # define as globals since the trainer does not have a memory.
best_min_metric, best_inception, best_fid = 100000000, 0, 1000000
best_min_ndb, ndb = 100000000, None


def gen_images(gen, n=50000, batchsize=100, seed=None, z=None):
    ims = []
    xp = gen.xp
    if seed is not None:
        xp.random.seed(seed=seed)
    for i in range(0, n, batchsize):
        with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
            x = gen(batchsize, z=z)
        x.unchain_backward()
        x_cpu = chainer.cuda.to_cpu(x.data)
        del x
        x_cpu = np.asarray(np.clip(x_cpu * 127.5 + 127.5, 0.0, 255.0), dtype=np.uint8)
        ims.append(x_cpu)
    ims = np.asarray(ims)
    # # the line below is only for images; synthetic might differ in number of dimensions.
    _, _, c, h, w = ims.shape
    ims = ims.reshape((n, c, h, w))
    return ims


def gen_images_with_condition(gen, c=0, n=500, batchsize=100, z=None):
    # # used to synthesize images with condition c, i.e. pass to the generator the
    # # variable c.
    ims = []
    xp = gen.xp
    for i in range(0, n, batchsize):
        with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
            if isinstance(c, np.ndarray) and len(c.shape) == 2 and c.shape[0] == batchsize:
                y = xp.asarray(c, dtype=xp.int32)
            else:
                y = xp.asarray([c] * batchsize, dtype=xp.int32)
            x = gen(batchsize, y=y, z=z)
        x = chainer.cuda.to_cpu(x.data)
        x = np.asarray(np.clip(x * 127.5 + 127.5, 0.0, 255.0), dtype=np.uint8)
        ims.append(x)
    ims = np.asarray(ims)
    _, _, c, h, w = ims.shape
    ims = ims.reshape((n, c, h, w))
    return ims


def sample_generate_light(gen, dst, rows=5, cols=5, batchsize=5, seed=0):
    @chainer.training.make_extension()
    def make_image(trainer):
        np.random.seed(seed)
        n_images = rows * cols
        x = gen_images(gen, n_images, batchsize=batchsize)
        _, c, H, W = x.shape
        x = x.reshape((rows, cols, c, H, W))
        x = x.transpose(0, 3, 1, 4, 2)
        x = x.reshape((rows * H, cols * W, c))
        if c == 1:
            x = np.concatenate([x, x, x], axis=2)
        preview_dir = '{}/preview'.format(dst)
        preview_path = preview_dir + '/image_latest.png'
        if not os.path.exists(preview_dir):
            os.makedirs(preview_dir)
        Image.fromarray(x).save(preview_path)

    return make_image


def sample_generate(gen, dst, rows=10, cols=10, batchsize=10, seed=0):
    @chainer.training.make_extension()
    def make_image(trainer):
        print('in sample generation: ', trainer.updater.iteration)
        np.random.seed(seed)
        n_images = rows * cols
        x = gen_images(gen, n_images, batchsize=batchsize)
        _, c, h, w = x.shape
        x = x.reshape((rows, cols, c, h, w))
        x = x.transpose(0, 3, 1, 4, 2)
        x = x.reshape((rows * h, cols * w, c))
        if c == 1:
            x = np.concatenate([x, x, x], axis=2)
        if c > 3:
            x = x[:, :, :3]
        preview_dir = '{}/preview'.format(dst)
        preview_path = preview_dir + '/image{:0>8}.png'.format(trainer.updater.iteration)
        if not os.path.exists(preview_dir):
            os.makedirs(preview_dir)
        Image.fromarray(x).save(preview_path)

    return make_image


def sample_generate_conditional(gen, dst, rows=10, n_classes=1000, seed=0, classes=None):
    """Visualization of rows*cols images randomly generated by the generator."""
    if classes is None:
        classes = np.arange(10) * (n_classes / 10)
    print('Sample visualization classes: ', classes)
    # # update the rows if less than the clases.
    rows = min(rows, len(classes))

    @chainer.training.make_extension()
    def make_image(trainer=None):
        np.random.seed(seed)
        xp = gen.xp
        with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
            x = []
            for c in classes:
                x.append(gen_images_with_condition(gen, c=c, n=rows, batchsize=rows))
            x = np.concatenate(x, 0)
        _, c, h, w = x.shape
        x = x.reshape((rows, len(classes), c, h, w))
        x = x.transpose(0, 3, 1, 4, 2)
        x = x.reshape((rows * h, len(classes) * w, c))
        if c == 1:
            x = np.concatenate([x, x, x], axis=2)
        preview_dir = '{}/preview'.format(dst)
        preview_path = preview_dir + '/image{:0>8}.png'.format(
            trainer.updater.iteration if trainer is not None else None)
        if not os.path.exists(preview_dir):
            os.makedirs(preview_dir)
        Image.fromarray(x).save(preview_path)

    return make_image

def divergence_gen(gen, gt_db, batch=1000, metric='kl', normalize=False, 
                   n_bins=100, whitening=True, classes=None, **kwargs):
    """ 
    Given a generator and the gt function (the one generator 
    tries to approximate), we measure the discrepancy of the
    generated from the gt signals. 
    """
    # # generate some samples.
    batch = gt_db.shape[0]
    if classes is None:
        gen_samples = gen_images(gen, n=batch, batchsize=batch)
    else:
        # # conditional case.
        gen_csamples, n_ms = [], int(batch // len(classes) + 10)
        for cl in classes:
            x = gen_images_with_condition(gen, n=n_ms, c=cl, batchsize=n_ms)
            gen_csamples.append(x)
        gen_csamples = np.concatenate(gen_csamples, 0)
        gen_samples = gen_csamples[:gt_db.shape[0]]
    if len(gt_db.shape) != 2:
        gt_db = gt_db.reshape((batch, -1))
    if len(gen_samples.shape) != 2:
        gen_samples = gen_samples.reshape((batch, -1))
    if gen_samples.dtype == np.uint8:
        gen_samples = gen_samples.astype(np.float32)
    if normalize:
        # # Given that gen_images have a range [0, 255], normalize
        # # the images in the [-1, 1] range for the KNN.
        gen_samples1 = gen_samples / 127.5 - 1
    else:
        gen_samples1 = gen_samples

    if metric == 'ndb':
        global ndb
        if ndb is None:
            ndb = NDB(training_data=gt_db, number_of_bins=n_bins, whitening=whitening)
        metric_val = ndb.evaluate(gen_samples)
        chainer.reporter.report({'ndb': metric_val['NDB']})
        chainer.reporter.report({'JS': metric_val['JS']})
        diver = metric_val['NDB']
    else:
        # # define an estimator (e.g. KL divergence).
        est = KNNDivergenceEstimator(div_funcs=[metric], Ks=[3], clamp=False)
        # # fit and return the result.
        res_diver = est.fit_transform([gt_db, gen_samples])
        try:
            diver = res_diver[0, 1]
        except:
            diver = res_diver[0][0][0, 1]
        chainer.reporter.report({'kl': diver})
    return diver

    
def divergence_trainer(gen, db, metric='kl', export_best=True, **kwargs):
    """
    Chainer extension for evaluating the divergence of the generator from gt.
    """
    @chainer.training.make_extension()
    def evaluation(trainer=None):
        
        for met in metric:
            metric_val = divergence_gen(gen, db, metric=met, **kwargs)
            if export_best and trainer is not None:
                # # compare with the best score (per metric).
                global best_min_metric, best_min_ndb
                if 'kl' in met and metric_val < best_min_metric:
                    # # export if it has the best score so far (kl).
                    best_min_metric = metric_val
                    ext = extensions.snapshot_object(gen, '{}_best.npz'.format(gen.__class__.__name__))
                    ext(trainer)
                elif 'ndb' in met and metric_val < best_min_ndb:
                    # # export if it has the best score so far (ndb).
                    best_min_ndb = metric_val
                    ext = extensions.snapshot_object(gen, '{}_best_ndb.npz'.format(gen.__class__.__name__))
                    ext(trainer)

    if isinstance(metric, str):
        metric = [metric]
    return evaluation


def load_inception_model(path=None, gpu=0):
    path = path if path is not None else "%s/inception/inception_score.model" % os.path.dirname(__file__)
    model = Inception()
    serializers.load_hdf5(path, model)
    if gpu >= 0:
        model.to_gpu()
    return model


def calc_inception(gen, batchsize=10, dst=None, path=None, n_ims=50000, splits=10):
    @chainer.training.make_extension()
    def evaluation(trainer=None):
        model = load_inception_model(path)
        ims = gen_images(gen, n_ims, batchsize=batchsize).astype("f")
        mean, std = inception_score(model, ims, splits=splits)
        chainer.reporter.report({
            'inception_mean': mean,
            'inception_std': std
        })
        if dst is not None:
            preview_dir = '{}/stats'.format(dst)
            preview_path = preview_dir + '/inception_score_{:0>8}.txt'.format(
                trainer.updater.iteration if trainer is not None else None)
            np.savetxt(preview_path, np.array([mean, std]))
        # # export the best model.
        global best_inception
        if trainer is not None and best_inception < mean:
            ext = extensions.snapshot_object(gen, gen.__class__.__name__ + '_best_inception.npz')
            ext(trainer)
            best_inception = mean

    return evaluation


def get_mean_cov(model, ims, batch_size=100, verbose=False):
    n, c, w, h = ims.shape
    n_batches = int(math.ceil(float(n) / float(batch_size)))
    xp = model.xp
    ys = xp.empty((n, 2048), dtype=xp.float32)
    for i in range(n_batches):
        if verbose:
            print('Running batch', i + 1, '/', n_batches, '...')
        batch_start = (i * batch_size)
        batch_end = min((i + 1) * batch_size, n)
        ims_batch = ims[batch_start:batch_end]
        ims_batch = Variable(xp.asarray(ims_batch, dtype=xp.float32))

        # Resize image to the shape expected by the inception module
        if (w, h) != (299, 299):
            ims_batch = F.resize_images(ims_batch, (299, 299))  # bilinear

        # Feed images to the inception module to get the features
        with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
            y = model(ims_batch, get_feature=True)
        ys[batch_start:batch_end] = y.data

    mean = xp.mean(ys, axis=0).get()
    # cov = F.cross_covariance(ys, ys, reduce="no").datasets.get()
    cov = np.cov(ys.get().T)
    return mean, cov


def monitor_largest_singular_values(dis, dst):
    @chainer.training.make_extension()
    def evaluation(trainer=None):
        def _l2normalize(v, eps=1e-12):
            return v / (((v ** 2).sum()) ** 0.5 + eps)

        xp = dis.xp
        links = [[name, link] for name, link in sorted(dis.namedlinks())]
        sigmas = []
        for name, link in links:
            if isinstance(link, SNConvolution2D):
                W, u = link.W, link.u
                W_mat = W.reshape(W.shape[0], -1)
                sigma, _, _ = max_singular_value(W_mat, u)
                W_bar = cuda.to_cpu((W_mat.data / xp.squeeze(sigma.data)))
                _, s, _ = svd(W_bar)
                _sigma = s[0]
                print(name.strip('/'), _sigma)
                sigmas.append([name.strip('/'), _sigma])

        if dst is not None:
            preview_dir = '{}/sigmas'.format(dst)
            if not os.path.exists(preview_dir):
                os.makedirs(preview_dir)
            preview_path = preview_dir + '/sigmas_{:0>8}.txt'.format(
                trainer.updater.iteration if trainer is not None else None)
            with open(preview_path, 'wb') as f:
                np.savetxt(f, np.array(sigmas, dtype=np.str), delimiter=" ", fmt="%s")

    return evaluation


def FID(m0, c0, m1, c1):
    ret = 0
    ret += np.sum((m0 - m1) ** 2)
    ret += np.trace(c0 + c1 - 2.0 * scipy.linalg.sqrtm(np.dot(c0, c1)))
    return np.real(ret)


def calc_FID(gen, batchsize=100, stat_file="%s/cifar-10-fid.npz" % os.path.dirname(__file__), dst=None, path=None,
             n_ims=5000):
    """Frechet Inception Distance proposed by https://arxiv.org/abs/1706.08500"""

    @chainer.training.make_extension()
    def evaluation(trainer=None):
        model = load_inception_model(path)
        stat = np.load(stat_file)
        ims = gen_images(gen, n_ims, batchsize=batchsize).astype("f")
        with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
            mean, cov = get_mean_cov(model, ims)
        fid = FID(stat["mean"], stat["cov"], mean, cov)
        chainer.reporter.report({'FID': fid})
        if dst is not None:
            preview_dir = '{}/stats'.format(dst)
            preview_path = preview_dir + '/fid_{:0>8}.txt'.format(
                trainer.updater.iteration if trainer is not None else None)
            np.savetxt(preview_path, np.array([fid]))

        # # export the best model.
        global best_fid
        if trainer is not None and best_fid > fid:
            ext = extensions.snapshot_object(gen, gen.__class__.__name__ + '_best_fid.npz')
            ext(trainer)
            best_fid = fid

    return evaluation

# For classification

def get_batch(iterator, xp):
    batch = iterator.next()
    batchsize = len(batch)
    x, y = [], []
    for j in range(batchsize):
        _x = batch[j][0]
        _y = batch[j][1]
        if isinstance(_x, (list, tuple)):
            for k in range(len(_x)):
                x.append(np.asarray(_x[k]).astype("f"))
                y.append(np.asarray(_y[k]).astype(np.int32))
        else:
            x.append(np.asarray(batch[j][0]).astype("f"))
            y.append(np.asarray(batch[j][1]).astype(np.int32))
    x = xp.asarray(x)
    y = xp.asarray(y, dtype=xp.int32)
    return x, y



def validation_loss_and_acc(cls, iterator, n=50000, dis=None):

    @chainer.training.make_extension()
    def _evaluate(trainer):
        iterator.reset()
        losses = []
        accs = []
        for i in range(0, n, iterator.batch_size):
            x, y = get_batch(iterator, cls.xp)
            with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):
                if dis is not None:
                    _, x = dis(x, return_feature=True)
                logit = cls(x)
                loss = F.softmax_cross_entropy(logit, y)
                acc = F.accuracy(logit, y)
                losses.append(chainer.cuda.to_cpu(loss.array))
                accs.append(chainer.cuda.to_cpu(acc.array))
        chainer.reporter.report({
            'val_loss': np.mean(np.asarray(losses)),
            'val_acc': np.mean(np.asarray(accs))
        })

    return _evaluate
